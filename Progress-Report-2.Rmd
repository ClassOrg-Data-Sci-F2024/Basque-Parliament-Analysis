---
title: "Progress-Report-2"
author: "Claire McLean"
date: "2024-10-28"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Progress Report 2

## Here, I will begin the next steps of my data cleaning.

## Step 1: Performed in Python
In this step, I wrote a script to filter the train.tsv file provided in the Hugging Face dataset folder to include only the rows/utterances that contain the following keywords:

['hablante', 'euskera', 'lenguaje', 'idioma', 'aprendizaje', 'lingüístico', 'lingüística']

These keywords were chosen because they demonstrate the relevance of the utterance to the concept of language, linguistics, or "speaker".

The final output of the script was a smaller .csv file containing only the rows that will be relevant to my analysis. This dataframe will be further cleaned in later steps.

This script has been included in my Progress Report 2, but will most likely not be part of my final submission.

## Step 2: Data Wrangling in R

First, import dependencies:
```{r}
library("tidyverse")
library("readr")
```


Next, read in the .csv file:
```{r}
rel_data <- read_csv("BS_RelData.csv")
```
Reducing size by only including first 150 rows:
```{r}
small_data <- rel_data %>% filter()
```


